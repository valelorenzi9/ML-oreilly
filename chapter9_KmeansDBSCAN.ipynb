{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "according-oakland",
   "metadata": {},
   "source": [
    "### Unsupervised Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-compromise",
   "metadata": {},
   "source": [
    "**Clustering** = groups similar instances together into clusters. Used for: \n",
    " * data analysis: run clustering and analyze each cluster separately\n",
    " * customer segmentation: cluster customers based on their purchases and activity on a website.\n",
    " * recommender systems\n",
    " * search engines: apply clustering to all the images in a database. When a user provides a reference image, we need to use the trained model to find the image's cluster and return all the images from this cluster.  \n",
    " * image segmentation: clustering pixel according to their color, then replace each pixel's color with the mean color of its cluster to reduce the number of different colors in the image. \n",
    " * semi-supervised learning: if we only have a few labels, we can perform clustering and propagate the labels to all the instances in the same cluster.   \n",
    " * dimensionality reduction: once a dataset has been clustered, it is usually possible to measure each instance's affinity with each cluster --> an instance's feature vector can then be replace by the vector of cluster affinities. If there are k clusters, the vector will be k-dimensional. \n",
    " * anomaly detection: any instance that has low affinity to all the clusters is likely to be an anomaly. \n",
    "\n",
    "**Anomaly detection** = learn what *normal* data looks like and use that to detect abnormal instances: \n",
    " * defective items on a production line \n",
    " * new trend in a time series \n",
    "\n",
    "**Density estimation** = estimate the probability density function of the random process that generated the dataset. Used for: \n",
    " * anomaly detection --> instances located in very low density regions are likely to be anomalies \n",
    " * data analysis and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-nitrogen",
   "metadata": {},
   "source": [
    "### 1. Clustering algorithms \n",
    "\n",
    "#### 1a. K-Means \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "muslim-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris \n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nominated-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "\n",
    "k = 4\n",
    "kmeans = KMeans(n_clusters = k)\n",
    "y_pred = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "laden-tucson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 3, 3, 3, 0, 3, 0, 3, 0, 3, 0, 0, 0, 0, 3, 0, 3,\n",
       "       0, 0, 3, 0, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 3, 0, 3, 3, 3,\n",
       "       0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 2, 3, 2, 3, 2, 2, 0, 2, 2, 2,\n",
       "       3, 3, 2, 3, 3, 2, 2, 2, 2, 3, 2, 3, 2, 3, 2, 2, 3, 3, 2, 2, 2, 2,\n",
       "       2, 3, 3, 2, 2, 3, 3, 2, 2, 2, 3, 2, 2, 2, 3, 3, 2, 3], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred # labels the instance was assigned to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prostate-pierre",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.53214286, 2.63571429, 3.96071429, 1.22857143],\n",
       "       [5.006     , 3.428     , 1.462     , 0.246     ],\n",
       "       [6.95      , 3.10666667, 5.86666667, 2.15333333],\n",
       "       [6.25714286, 2.86190476, 4.85      , 1.63333333]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vertical-steam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "X_new = np.array([[0, 2, 3, 2]])\n",
    "kmeans.predict(X_new) # Assign new instance to the cluster whose centroid is the closest "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-fantasy",
   "metadata": {},
   "source": [
    "**Hard clustering** = assign each instance to a single cluster \n",
    "\n",
    "**Soft clustering** = give each instance a score per cluster. It can either be a distance between the instance and the centroid or a similarity score like a Gaussian Radial Basis Function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "geographic-seller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.70322814, 5.70448771, 7.60055919, 6.59178739]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.transform(X_new) # Gives the distances from each cluster centroid "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-inquiry",
   "metadata": {},
   "source": [
    "#### Algorithm\n",
    "\n",
    " 1. Place centroids randomly = pick k instances at random and use their locations as centroids \n",
    " 2. Label the instances \n",
    " 3. Update the centroids \n",
    " 4. Iterated steps 2 and 3 until the centroids stop moving \n",
    "\n",
    "The algorithm is guaranteed to converge in a finite number of steps. --> but, it is not guaranteed to converge to the global optimum, and this depends on the centroid initialization!\n",
    "\n",
    "**Computational complexity** = linear in the number of instances, number of clusters and number of dimensions. \n",
    "\n",
    "**Centroid initialization methods**\n",
    "\n",
    " * If we happen to know approximately where the centroids should be, we can set the *init* hyperparameter to a numpy array containing the list of centroids and set *n_init* to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "departmental-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_init = np.array([[5, 3, 1, 0.2], [6, 2, 4 , 1], [6, 3, 5, 2], [5, 2, 3, 1]])\n",
    "kmeans = KMeans(n_clusters = 4, init = good_init, n_init = 1)\n",
    "y_pred = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-demand",
   "metadata": {},
   "source": [
    " * Run the algorithm multiple times with different random initializations and keep the best solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "junior-european",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.25600931571815"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-qatar",
   "metadata": {},
   "source": [
    "**Inertia** = performance metric for clustering, which is the mean squared distance between each instance and its closest centroid. --> the KMeans class runs the algorithm *n_init* times and keeps the model with the lowest intertia. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-toner",
   "metadata": {},
   "source": [
    " * KMeans++ initialization algorithm: \n",
    "  1. Take one centroid $c^{(1)}$, chosen uniformly at random from the dataset \n",
    "  2. Take a new centroid $c^{(i)}$, choosing an instance $x^{(i)}$ with probability $D(x^{(i)})^{2}$ / $\\sum_{j = 1}^{m} D(x^{(j)})^{2}$, where $D(x^{(i)})$ is the distance between the instance $x^{(i)}$ and the closest centroid that was already chosen. This probability distribution ensures that instances farther away from already chosen centroids are much more likely to be selected as centroids \n",
    "  3. Repeat the previous steps until all k centroids have been chosen \n",
    "  \n",
    "\n",
    "The KMeans class uses this initialization method by default.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-confusion",
   "metadata": {},
   "source": [
    "#### Accelerated K-Means and mini-batch K-Means \n",
    "\n",
    " * Exploit triangle inequality + keep track of the lower and upper bounds for distances between instances and centroids --> accelerates the algorithm by avoiding unnecessary distance calculations \n",
    " * Use mini-batches + move the centroids just slightly at each iteration --> possible to cluster huge datasets that do not fit in memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "comparable-charter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniBatchKMeans(n_clusters=5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans \n",
    "\n",
    "minibatch_kmeans = MiniBatchKMeans(n_clusters = 5)\n",
    "minibatch_kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-analysis",
   "metadata": {},
   "source": [
    "**Finding the optimal number of clusters**\n",
    "\n",
    "Inertia is not a good performance metric for choosing k because it keeps getting lower as we increase k --> the more clusters there are, the closer each instance will be to its closest centroid, and therefore the lower the inertia!\n",
    "\n",
    " * Elbow method with inertia plot --> pick k where inertia starts decreasing more slowly \n",
    " * Silhouette score = mean silhouette coefficient over all instances. --> varies between -1 and +1\n",
    " \n",
    "$(b - a)$ / $max(a, b)$\n",
    "\n",
    "where $a$ is the mean distance to the other instances of the same cluster (intra-cluster distance) and $b$ is the mean nearest-cluster distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "designing-cemetery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49745518901737446"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette_score(X, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-budapest",
   "metadata": {},
   "source": [
    "**Limits of K-Means**\n",
    "\n",
    "K-Means does not behave well when clusters have: \n",
    " * varying sizes \n",
    " * different densities \n",
    " * nonspherical shapes \n",
    "\n",
    "\n",
    "**!** Important to **scale the input features** before running K-Means otherwise the clusters might be very stretched and therefore result in poor performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-range",
   "metadata": {},
   "source": [
    "#### K-Means for Image Segmentation\n",
    "\n",
    "Image segmentation is the task of partitioning an image into multiple segments. \n",
    "\n",
    " * Semantic segmentation = all pixels that are part of the same object type get assigned to the same segment. \n",
    " * Instance segmentation = all pixels that are part of the same individual object are assigned to the same segment. \n",
    " * Color segmentation = all pixels of the same color are assigned to the same segment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread \n",
    "import os\n",
    "\n",
    "image = imread(os.path.join(\"images\", \"unsupervised_learning\", \"ladybug.png\"))\n",
    "image.shape\n",
    "X = image.reshape(-1, 3)\n",
    "kmeans = KMeans(n_clusters = 8).fit(X)\n",
    "segmented_img = kmeans.cluster_centers_[kmenas.labels_]\n",
    "segmented_img = segmented_img.reshape(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-motion",
   "metadata": {},
   "source": [
    "#### K-Means for preprocessing \n",
    "\n",
    "Clustering can be an efficient preprocessing step before supervised learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "casual-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "X_digits, y_digits = load_digits(return_X_y = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "coated-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_digits, y_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bigger-postcard",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/my-conda-envs/scanpy_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "shared-ethernet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "meaning-transfer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/my-conda-envs/scanpy_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('kmeans', KMeans(n_clusters=50)),\n",
       "                ('logreg', LogisticRegression())])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline \n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('kmeans', KMeans(n_clusters = 50)),\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ranging-bracelet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9644444444444444"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "param_grid = dict(kmeans__n_clusters = range(2,100))\n",
    "grid_clf = GridSearchCV(pipeline, param_grid, cv = 3)\n",
    "grid_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-mining",
   "metadata": {},
   "source": [
    "#### K-Means for semi-supervised learning \n",
    "\n",
    "Semi-supervised learning = plenty of unlabeled instances and few labeled instances. \n",
    "\n",
    " * Label representative images \n",
    " * Propagate the labels to all instances in the same cluster (**label propagation**) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "handy-venue",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/my-conda-envs/scanpy_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_labeled = 50\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train[:n_labeled], y_train[:n_labeled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "lonely-method",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bibliographic-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50 \n",
    "kmeans = KMeans(n_clusters = k)\n",
    "X_digits_dist = kmeans.fit_transform(X_train)\n",
    "representative_digit_idx = np.argmin(X_digits_dist, axis = 0)\n",
    "X_representative_digits = X_train[representative_digit_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-collapse",
   "metadata": {},
   "source": [
    "#### 1b. DBSCAN \n",
    "\n",
    " * For each instance, count how many instances are located within a small distance $\\epsilon$ from it --> instance's **$\\epsilon$ - neighborhood** \n",
    " * If an instance has at least min_samples instances in its **$\\epsilon$ - neighborhood** it is considered a **core instance** --> core instances are those located in dense regions. \n",
    " * all instances in the neighborhood of a core isntance belong to the same cluster --> long sequence of neighboring core instances forms a single cluster \n",
    " * any instance that is not a core instance and does not have its own neighborhood is considered an **anomaly** \n",
    "\n",
    "\n",
    "**!** DBSCAN works wee if the clusters are dense enough and are well separated by low-density regions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "frequent-wichita",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN(eps=0.05)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN \n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples = 1000, noise = 0.05)\n",
    "dbscan = DBSCAN(eps = 0.05, min_samples = 5)\n",
    "dbscan.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "recognized-north",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  5,  1,  0, -1,  0,  0,  2, -1,  0,  0,  0,  1,  2,  3,  0,  2,\n",
       "        1,  0,  3,  0,  3,  4,  3, -1,  1,  0,  1,  2,  5,  3,  3,  6, -1,\n",
       "        1, -1,  4,  6,  0,  0,  6,  1,  0,  2,  2,  4,  1,  0,  1,  1,  0,\n",
       "        1,  3,  1,  3,  1,  3,  4,  3,  1,  0,  0,  3,  2,  0, -1,  3,  5,\n",
       "        2,  0,  1,  1,  3,  3,  4,  4,  0,  0, -1,  1,  2,  1,  0,  4,  0,\n",
       "       -1,  1,  5,  1,  0,  1,  3,  1,  5,  1,  2,  3,  1,  5,  1,  3,  1,\n",
       "       -1,  1,  3,  3,  4,  0,  0,  0,  1, -1,  3,  1,  1,  0,  4,  3,  0,\n",
       "        1,  0,  3,  4,  1,  2,  6,  3,  7,  2, -1,  1, -1,  1,  0,  7,  0,\n",
       "        1,  0,  4,  4,  1,  1,  1,  5,  3,  0,  5,  1,  1,  0,  5,  1,  0,\n",
       "        0, -1,  0, -1,  2,  2,  1,  2,  1,  3,  5,  2,  1,  1,  0,  1, -1,\n",
       "        1,  5,  1,  0,  0,  1,  2,  1,  3,  5,  1, -1,  2,  3,  6,  1,  1,\n",
       "        0,  3,  3,  0, -1,  1,  0,  0,  1,  0,  1, -1,  1,  3,  2,  1,  0,\n",
       "        3, -1,  3,  2,  1, -1,  3,  6,  1,  1, -1,  7,  1,  1,  0,  0,  2,\n",
       "        1,  5,  4,  4,  2,  0,  3,  3,  0,  1,  1, -1,  0,  0,  3,  0,  5,\n",
       "        3,  1,  1,  3,  1, -1,  1,  1,  1,  1,  0,  5,  4,  1,  1,  1, -1,\n",
       "        1,  0,  1,  0,  1,  1,  5,  1,  0, -1,  2,  1,  3,  4,  1,  0,  1,\n",
       "        0,  6, -1,  1,  2,  0,  2,  1,  0,  3,  1,  0,  7,  0,  1,  0,  3,\n",
       "        1,  2,  3,  2,  0,  1,  2,  3,  0,  1,  1,  0,  2,  1,  3,  5, -1,\n",
       "        2,  7,  5,  0,  5,  3,  0,  3, -1,  2,  1,  1,  0,  1,  0,  1,  0,\n",
       "        2,  1,  2,  0,  0,  3, -1,  1,  6,  1,  2,  1,  0,  1,  1,  0,  1,\n",
       "        6,  1,  1,  1,  0,  1,  0,  2,  0,  1,  4,  2,  6,  3,  3,  4,  1,\n",
       "        5,  0,  3,  1,  2,  1,  3, -1,  3, -1,  3,  3, -1,  1,  0,  1,  1,\n",
       "        3,  3,  2,  3,  0,  1,  2,  5,  2,  1,  1,  0,  1,  0,  1,  1, -1,\n",
       "        0,  3,  1,  2,  0,  5,  2,  0,  0,  5,  1,  7, -1,  1,  2,  1,  1,\n",
       "        3,  0,  5,  0,  5,  3,  2,  2,  0,  0,  1,  1,  0,  3,  5,  3,  5,\n",
       "        3,  2,  1, -1,  1,  5, -1,  5,  1,  3,  0,  5,  0,  0,  1, -1,  3,\n",
       "        0,  5, -1,  3,  2,  3,  4,  5,  1,  0,  3,  1,  3,  4,  1,  1, -1,\n",
       "        5, -1,  1,  1,  0,  0,  3,  5,  3,  0,  0,  6,  4,  1,  3,  0,  0,\n",
       "        2,  1,  1,  3,  1,  1,  3,  3,  2,  5,  1,  1,  1,  2,  0,  1,  0,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1, -1,  2,  3,  5,  1,  4,  1,  6,  5,\n",
       "        0,  1, -1,  1,  2, -1,  5,  2,  5,  1,  1,  2,  4,  1,  0,  1,  1,\n",
       "        2,  2,  1,  3,  2,  0,  0,  1,  1,  1,  1,  2,  5,  1,  5,  1,  1,\n",
       "        2,  5,  1,  0,  1,  1,  1,  2,  4,  0,  1,  3,  4,  0,  5,  1,  1,\n",
       "        2,  3,  1,  1,  1,  1,  1,  3,  0,  0, -1, -1,  3,  7,  1,  1,  1,\n",
       "        1,  1,  0,  0,  1,  0,  0,  3,  1,  1,  0,  1,  0,  3,  0,  1,  0,\n",
       "        0,  1,  0, -1,  0,  0,  1,  1,  0, -1,  0,  3,  3,  1,  3,  4,  3,\n",
       "        0,  1, -1,  3,  0,  0,  5, -1,  1,  3,  1,  1,  0,  5,  0,  3,  0,\n",
       "        3,  3,  1,  3,  2,  2,  0,  2,  1,  6,  1,  6,  3,  1,  1,  5,  0,\n",
       "        0,  3,  0,  0,  2,  1,  5,  1,  4,  1,  0,  1,  1,  4,  5,  7, -1,\n",
       "        2,  2,  1,  1,  1,  0,  0,  5,  0,  0,  1,  3,  2,  4,  0,  4,  0,\n",
       "        4,  7,  0,  2,  1,  3,  1,  6,  1,  1,  3,  5,  2,  3,  1,  3,  0,\n",
       "        0,  2,  0,  0,  1,  2,  2,  3,  3,  0,  7,  1,  0,  1,  0,  1,  0,\n",
       "       -1,  3,  5,  0,  0,  3, -1,  5,  4,  6,  2,  1, -1,  3,  6,  1,  3,\n",
       "       -1,  0,  3,  1,  0, -1,  1,  1,  1,  3,  1,  0,  0, -1,  0,  0,  1,\n",
       "        1,  4,  3,  0,  0, -1,  2,  5,  3,  1,  2, -1,  1,  4,  3,  0,  3,\n",
       "        0,  2,  0,  5,  2,  1, -1,  5,  0,  1,  1,  5,  1,  3,  2,  3,  1,\n",
       "        1,  0,  1,  5,  0, -1,  1, -1,  0,  2,  1,  1,  0,  3,  3,  0,  5,\n",
       "        3, -1,  1, -1, -1,  4,  5,  3, -1,  0,  3,  1, -1,  0,  0,  3,  1,\n",
       "        1,  1,  0,  0,  7,  0,  0,  0, -1,  3,  1,  1,  0,  0,  0,  0,  1,\n",
       "        1,  0,  2,  0,  0,  1,  1,  1,  4,  0,  0,  1,  3,  0,  4,  0,  1,\n",
       "        1,  3,  4, -1,  1,  0,  5,  1,  2,  4,  0,  2,  0,  1,  1,  4,  3,\n",
       "       -1,  1,  0,  0, -1,  1,  0,  0,  1,  2,  1,  1,  1,  2,  5,  1,  6,\n",
       "        3,  5,  1,  0,  1,  4,  0,  0,  0,  0,  6,  4,  3,  1,  1,  4,  0,\n",
       "        1,  6,  3,  1,  0, -1,  1, -1,  3,  0,  1, -1,  3,  0,  0,  3,  1,\n",
       "        1,  1, -1,  0,  0,  1,  1,  5, -1,  1, -1,  0,  3,  3,  3,  1,  0,\n",
       "        1,  1,  1,  0,  3,  3,  1,  0, -1,  3, -1,  0,  3,  0,  1,  1,  1,\n",
       "        2,  0,  3,  3,  1,  1,  3, -1,  3,  6,  1,  0, -1,  0, -1,  2, -1,\n",
       "        1,  0,  1,  5,  1,  3,  2,  5,  3,  1,  0,  1,  1,  0, -1,  1,  3,\n",
       "        5,  1,  2,  1,  5,  0, -1,  2,  1,  0,  3, -1,  3,  1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-correspondence",
   "metadata": {},
   "source": [
    "Instances that have a cluster index of -1 are considered anomalies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "widespread-stanford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dbscan.core_sample_indices_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-identity",
   "metadata": {},
   "source": [
    " * DBSCAN does not have a predict() method, meaning that it cannot predict which cluster a new instance belongs to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "combined-swift",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=50)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 50)\n",
    "knn.fit(dbscan.components_, dbscan.labels_[dbscan.core_sample_indices_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "combined-heading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 2, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array([[-0.5, 0], [0, 0.5], [1, -0.1], [2, 1]])\n",
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "earned-mongolia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.2 , 0.04, 0.76, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.32, 0.68, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict_proba(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-victim",
   "metadata": {},
   "source": [
    " * Can identify number of clusters of any shape\n",
    " * Robust to outliers \n",
    " * 2 hyperparameters: min_samples and eps "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-lesbian",
   "metadata": {},
   "source": [
    "#### 1.c Other clustering algorithms\n",
    "\n",
    " * **Agglomerative clustering** = a hierarchy of clusters is built from the bottom up. \n",
    " * **BIRCH** = during training, it builds a tree structure containing just enough information to quickly assign each new instance to a cluster without having to store all the instances in the tree --> uses limited memory, good for huge datasets. \n",
    " * **Mean-Shift** = places a circle centered on each instance, and for each instance computes the mean of all the instances located within it and shifts the circle so that it is centered on the mean. iterate this mean-shifting step until the circles stop moving. Similar to DBSCAN. Has only one hyperparameter: radius of the circles. Not suited for large datasets. \n",
    " * **Affinity propagaton** = uses a voting system where instances vote for similar instances to be their representatives, and once the algorithm converges each representative and its voters form a cluster. Not suited for large datasets. \n",
    " * **Spectral clustering** = takes a similarity matrix between instances the creates a low dimensional embedding from it. Then uses another clustering algorithm on this low-dimensional space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-recording",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scanpy_env",
   "language": "python",
   "name": "scanpy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
